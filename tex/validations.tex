\chapter{Experimental Validation} \label{chap:validations}

In this chapter, we demonstrate the behaviours generated by Curiosity-Based Learning Algorithm (CBLA) on an interactive art sculpture. We first investigated the behaviour of the simplest form of a CBLA system, one with a single node with one sensor and one actuator. This allows us to visualize the exploration pattern of the CBLA engine in two- or three-dimensional space. Then, we applied the algorithm on a small multi-node system with shared input variables. We observed its self-learning behaviours as well as the way it responds to external disturbances. After that, we constructed a small scale interactive sculptural system in the form of four-cluster test bed. In addition to shared inputs, virtual inputs were introduced to connect the different nodes. We investigated the different emergent behaviours resulting from different connection schemes. Finally, we conducted a formal user study using the test bed. Participants were invited to interact with the sculpture and report on their interest levels. The observations collected in this user study enabled us to understand the relationship between the participants' behaviours and engagement level under different conditions as well as different configurations of the CBLA system.

\section[Single Node Experiment]
{Single Node Experiment
	\footnote{An early version of this section has been published at IROS 2015 \cite{Chan2015} }}\label{sec:single-node}

Although the CBLA was designed for a distributed system with multiple nodes, it might not be easy to visualize the modelling process due to the high-dimensionality of the data and the models. To demonstrate the action selection pattern and the learning process, the CBLA was first tested on a simple toy example which is easily visualizable in 3-dimensional space. In this experiment, idle mode was disabled as the main objective was to observe and verify the exploration pattern of the CBLA. 

\subsection{Set-up}
The system in this experiment consists of a Light node, which is a single-input, single-output system. For the single-input system, S is a scalar value that represents the measurement from an ambient light sensor. It was recorded directly as a 12-bit value. M corresponds to the voltage duty cycle supplied to the LED, ranging from 0 to 100, with 0 being completely off (0V) and 100 being the maximum allowable voltage (~4.7V). The loop period is the time between each actuation and was set to 0.05s.

\subsection{Procedures and Expected Results}
In this experiment, the system ran for 2500 time steps without any external interference. 
Based on the reward structure, which favours learning first the most predictable regions of the state-space, the CBLA is expected to first explore the regions of the sensorimotor space that have low variance. Once the model in that region is learnt, it should move onto areas with higher variance.

\subsection{Results}

\Cref{fig:LED_ALS Model Evolution} shows the evolution of the prediction model and actual exemplars over time. As expected, the CBLA first selects actions associated with lower LED output levels, as this leads to measurements in the low variance regions. Over time, once the model in the low variance region is acquired, it moves toward higher brightness regions. \Cref{fig:LED_ALS Action Selection} shows that the best action and the actual selected action were completely random at first. The system then focused on the easy-to-learn areas in the lower brightness level. After that, it moved toward the higher brightness and harder-to-learn regions when it hadn't seen much improvement in the low brightness regions. After some exploration of the bright regions, prediction error is reduced in those regions, and the system returns again to explore the low-brightness region.  The resulting pattern of activation is interesting visually, as it results in non-random activations that have the potential to convey a notion of intent to the viewer. 
 
\begin{figure} [!htbp]
	\centering
	\includegraphics[width=0.95\textwidth]{"fig/validations/LED_ALS Model Evolution"}
	\caption[Evolution of the prediction models for the single node experiment]{Evolution of the prediction models for the single node experiment. Each point represents an exemplar. Points with the same colour are in the same region and the black lines are the cross-section of the linear models at S(t) = 0. The regions are numbered in the order that they were created. }
	\label{fig:LED_ALS Model Evolution}
\end{figure}

\begin{figure} [!htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{"fig/validations/LED_ALS Action Selection"}
	\caption[Action vs Time Graph for the single node experiment]{Action vs Time Graph for the single node experiment; the y-axis is the output of the LED M(t) and the x-axis is the time step. Orange dots represent the actual action taken and blue dots represent the best action given the sensorimotor context. The best action is defined as the action with the highest action value given the current state. Non-best actions are selected occasionally in order to explore the state space.}
	\label{fig:LED_ALS Action Selection}
\end{figure}

\Cref{fig:LED_ALS Mean Error vs Time} shows the mean error vs. time graph. Here we see that the prediction error quickly drops to a relatively low level. To improve its prediction further, the state-space was split into regions with low and high error. This allows the Region 1 (low variance region) to further reduce its prediction error.

\begin{figure}  [!htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{"fig/validations/LED_ALS Mean Error vs Time"}
	\caption[Mean error vs time graph for the single node experiment]{Mean error vs time graph for the single node experiment. Each colour represents a region and the colour code corresponds to final prediction model graph in Figure \ref{fig:LED_ALS Model Evolution} }
	\label{fig:LED_ALS Mean Error vs Time}
\end{figure}


In \Cref{fig:LED_ALS Action Value vs Time}, one can that see the action value of a region does not stay constant. This shows that as the prediction improves, the value of actions in that region decreases over time as the region becomes “learnt” and further learning potential decreases. 

\begin{figure} [!htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{"fig/validations/LED_ALS Action Value vs Time"}
	\caption[Action value vs time graph for the single node experiment]{Action value vs time graph for the single node experiment. Each colour represents a region and the colour code corresponds to final prediction model graph in Figure \ref{fig:LED_ALS Model Evolution} }
	\label{fig:LED_ALS Action Value vs Time}
\end{figure}

\FloatBarrier

\section[Multi-Node Experiment]
{Multi-Node Experiment
	\footnote{An early version of this section has been published at IROS 2015 \cite{Chan2015} }}\label{sec:multi-node}


In this Section, we describe a demonstration of an integrated system consisting of multiple CBLA Nodes. In addition, in this experiment, threshold-based Idle Mode was introduced. When the knowledge gain potential is low, a Node would enter Idle Mode and turn off its actuators. The behaviours of the system during the self learning period and its response to external interference was examined.

\subsection{Set-up}
The Light node was the same as in \Cref{sec:single-node}, with the addition of the shared IR proximity sensor. For the Fin node, the input variables are the average accelerometer readings of the three axes, and the shared IR proximity sensor reading over the 12.5s loop period; the output variable is the action of the Fin. There are four discrete actions: rest (0), lower to the right (1), lower to the left (2), and lower to the centre (3). Note that in this set up, the two types of nodes run with different loop periods, but coupling between them is accomplished through the shared IR sensor, which measures proximity as a 12-bit value. Note that in this experiment all four nodes share one single IR sensor. The set-up of the experiment is shown in \Cref{fig:Single_Cluster Set-up}.

\begin{figure} [!htbp]
	\centering
	\includegraphics[height=0.8\textheight]{"fig/validations/Single_Cluster Set-up"}
	\caption[Photograph of the Multi-Node Experiment set-up]{The set-up of the Multi-Node Experiment. The Light Node is shaded light blue, and the three Fin Nodes are shaded red, blue, and yellow. All four nodes share an IR proximity sensor in the purple circle.}
	\label{fig:Single_Cluster Set-up}
\end{figure}

\subsection{Procedures and Expected Results}
The system runs undisturbed until, after some initial learning, all of the nodes enter Idle Mode.  During this time, the IR proximity sensor pointed toward an empty area. Afterwards, a participant enters into the sculpture space in an area detectable by the IR proximity sensor. The system should then exit idle mode and begin learning the changed model introduced by the change in the environment.  Since the IR sensor is shared by all nodes, they are all expected to recognize the change and exit idle mode at approximately the same time. 

\subsection{Results}

\Cref{fig:Single_Cluster Action Value Vs Time} shows how the action values change over time for each of the nodes. The coloured lines represent the action values and each colour represents a region. The blue dots underneath the plot indicate when the node was in idle mode.

\begin{figure} [!htbp]
	\centering
	\includegraphics[width=1.0\textwidth]{"fig/validations/Single_Cluster Action Value Vs Time"}
	\caption[Action value vs time graph for the Single Cluster Experiment]{Action-value vs Time graph for the Light node (a) and the three Fin nodes (b), (c), (d).}
	\label{fig:Single_Cluster Action Value Vs Time}
\end{figure}

All the nodes first started learning their own models and entered idle mode. At around 390s, a human participant walked in front of the IR proximity sensor. This triggered a large reduction in action value at first, due to an increase in prediction error. However, as more data was collected, the action values for all four nodes quickly jumped up. This prompted the nodes to exit idle mode and begin generating actions to learn the model. After a period of readjustment, all four nodes re-entered idle mode after the new environment is learnt. 

\subsection{Discussion}

From \Cref{fig:Single_Cluster Action Value Vs Time}, one can see that the Light Node and the three Fin Nodes reacted to the environmental change nearly simultaneously. They exited the idle state and shifted to more exploratory actuation patterns. This showed that the shared sensor input variable was able link the CBLA engines together, even though they run independently at different frequencies. This experiment demonstrates that the reaction of the system to the changed environmental conditions creates an interaction with the visitor without any explicitly pre-programmed behaviours. The system appears to respond to the participant and their action, as its internal model of the environment cannot predict the behaviour of the participant. 

The system's intrinsic curiosity drives itself to perform actions and elicit responses from this new environment with the participant's presence, and update its prediction model. We anticipate that the visitors will find such behaviours engaging as the visitors can recognize that the sculpture is responding to their presence and action but they would not be able to easily predict how it might respond. This quality provides the CBLA System the potential to be more life-like than a prescripted or a random system. 



\section{Multi-Cluster Experiment}\label{sec:multi-cluster-experiment}

This experiment investigates the behaviours of the CBLA system on a four-cluster test bed described in \Cref{sec:multi-cluster-test-bed}. The test bed has two different network configurations: Spatial Mode, and Random Mode. Under different network configurations, the CBLA system is expected to behave differently. We hypothesize that users would find activations closer to them more relevant, and hence more interesting. Therefore, a metric to quantify this proximal activation is devised. The configuration with higher proximal activation is then used for subsequent user study described in \Cref{sec:user-study}.

\subsection{Set-up}\label{sec:multi-cluster-setup}

The multi-cluster test bed described in \Cref{sec:multi-cluster-test-bed} is used for this experiment. Since the goal of this experiment is to examine the behaviours of the CBLA system, the Prescripted Engine is not used in this experiment. In addition, within the CBLA Engine, a sigmoid function based idling function as described in \Cref{eqn:map_sigmoid} is used.

\subsection{Procedures}

The CBLA system first starts from a blank state without any preexisting exemplars or prediction models. It operates without any external interference for 300 seconds. After that an object is placed in front of the IR proximity sensor C3.F2.IR-S (referring to \Cref{fig:Spatial Global Mode}) for approximately 30 seconds. Then, the object is removed and the experiment continues on for another 120 seconds before the program is terminated.

This procedure was repeated three times for both Spatial Mode and Random Mode.

\subsection{Expected Results}

The level of output by an actuator is referred to as activation. All clusters are expected to have approximately the same level of activation during the initial learning period. After that, the amount of activation would reduce as the knowledge gain potential decreases. 

For Spatial Mode, it is expected that the activation as a result of the trigger at 300s point should be concentrated around the external interference location, which is near Cluster 3 ($C3$). On the other hand, for Random Mode, since Nodes are connected randomly, activation should be more spread out and no one cluster should have a larger than average level of activation. To quantify the activation level, metrics that evaluate the average total activation and average cluster activation are devised.

The total activation level at time step $t$ is the average output levels of all CBLA Nodes at time step $t$. It can be calculated as follows.
 
\begin{equation}\label{eqn:total_activation}
	a_t = \frac{1}{N} \sum_{j=0}^{N} \overline{m}_{jt} \text{, for all Nodes $j$}
\end{equation}
where $a_t$ is the total activation level at time step $t$; $N$ is the total number of CBLA Nodes; $\overline{m}_{jt}$ is the average output value of CBLA Node $j$ at time step $t$.

We are interested in the total activation level during the period immediately after the trigger was applied. Therefore, we compute the average total activation between the time of the trigger, $t_{trig}$, and the end of the readjustment period, $t_{readj}$, as follows.
\begin{equation}\label{eqn:average_total_activation}
\overline{a} = \frac{1}{| \left\{ a_{T_{trig}}, ... , a_{T_{readj}} \right\}|} \sum_{t=T_{trig}}^{T_{readj}} a_{t}
\end{equation}
where $\overline{a}$ is the average total activation from $T_{trig}$ to $T_{readj}$; and $| \left\{ a_{T_{trig}}, ..., a_{T_{readj}} \right\}|$ is the number of time steps between $T_{trig}$ and $T_{readj}$.

By looking at the cluster activation level, we can determine if the activations are concentrated in any particular cluster. 
To find the cluster activation level, we apply \eqref{eqn:total_activation}, but only for the CBLA Nodes within a particular cluster.
\begin{equation}\label{eqn:cluster_activation}
	a_{ct} = \frac{1}{N_c} \sum_{j=0}^{N_c} \overline{m_{jt}} \text{, for all Nodes $j$ in cluster $c$}
\end{equation}
where $a_{ct}$ is the cluster activation level at time step $t$; $N_c$ is the total number of CBLA Nodes in cluster $c$; $\overline{m}_{jt}$ is the average output value of CBLA Node $j$ at time step $t$.

Similarly, we can calculate the average cluster activation level during the period between $t_{trig}$ and $t_{readj}$ as follows.
\begin{equation}\label{eqn:average_cluster_activation}
\overline{a_c} = \frac{1}{| \left\{ a_{cT_{trig}}, ... , a_{cT_{readj}} \right\}|} \sum_{t=T_{trig}}^{T_{readj}} a_{ct}
\end{equation}
where $\overline{a_c}$ is the average cluster activation from $T_{trig}$ to $T_{readj}$; and $| \left\{ a_{cT_{trig}}, ..., a_{cT_{readj}} \right\}|$ is the number of time steps between $T_{trig}$ and $T_{readj}$.

In this experiment, we set $T_{readj}$ to 360s. This means that we are looking at the behaviours of the system within 60 seconds since the trigger at $T_{trig}$ = 300s. This time interval was chosen as we wanted to investigate how the responses of CBLA system in the relatively short time duration after users introduce the disturbances. We assumed that the users would not associate their actions with the activations that appear after more than 60s have passed.

\subsection{Results}

The average total activation and average cluster activation values for the Spatial and Random Mode trials are listed in \Cref{table:multi-cluster-results-spatial,table:multi-cluster-results-random}. The means of the results from each set of the three trials were used to interpret the results. 

\begin{table}[!htb]
	\caption[Results of the multi-cluster experiment for Spatial Mode]{Results of the multi-cluster experiments for Spatial Mode. The average total activation ($\overline{a}$) and the average cluster activation for each cluster ($\overline{a_{c1}}$, $\overline{a_{c2}}$, $\overline{a_{c3}}$, and $\overline{a_{c4}}$) were computed from $T_{trig}$ = 300s to  $T_{readj}$ = 360s.}
	\begin{center}
		\begin{tabular}{ | c | c | c | c | c | c |} 
			\hline
			\textbf{Trial \#} & \boldmath{$\overline{a}$}  & \boldmath{$\overline{a_{c1}}$}  & \boldmath{$\overline{a_{c2}}$} & \boldmath{$\overline{a_{c3}}$} & \boldmath{$\overline{a_{c4}}$} \\ 
			\hline
			\hline
			1 & 0.07209 & 0.06259 & 0.07982 & 0.09966 & 0.04629 \\
			\hline
			2 & 0.07306 & 0.08146 & 0.07130 & 0.08726 & 0.05219 \\
			\hline
			3 & 0.06915 & 0.08628 & 0.04721 & 0.08548 & 0.05761 \\
			\hlineB{3}	
			\textbf{Mean} & 0.07143	 & 0.07678 & 0.06611 & 0.09080 & 0.05203 \\
			\hline
			\textbf{Std. Dev.} & 0.00203 & 0.01251 & 0.01691 & 0.00772 & 0.00565 \\
			\hline			
		\end{tabular}
	\end{center}
	\label{table:multi-cluster-results-spatial}
\end{table}

\begin{table}[!htb]
	\caption[Results of the multi-cluster experiment for Random Mode]{Results of the multi-cluster experiments for Random Mode. The average total activation ($\overline{a}$) and the average cluster activation for each cluster ($\overline{a_{c1}}$, $\overline{a_{c2}}$, $\overline{a_{c3}}$, and $\overline{a_{c4}}$) were computed from $T_{trig}$ = 300s to  $T_{readj}$ = 360s. }
	\begin{center}
		\begin{tabular}{ | c | c | c | c | c | c |} 
			\hline
			\textbf{Trial \#} & \boldmath{$\overline{a}$}  & \boldmath{$\overline{a_{c1}}$}  & \boldmath{$\overline{a_{c2}}$} & \boldmath{$\overline{a_{c3}}$} & \boldmath{$\overline{a_{c4}}$} \\ 
			\hline
			\hline
			4 & 0.03297	& 0.04193 &	0.02686 & 0.02951 & 0.03358 \\
			\hline
			5 &	0.08062 & 0.08114 & 0.07884 & 0.08035 & 0.08218 \\
			\hline
			6 &	0.05953 & 0.06105 &	0.05732 & 0.06237 & 0.05737 \\
			\hlineB{3}	
			\textbf{Mean} & 0.07008	& 0.06137 &	0.05434	& 0.05741 & 0.05771  \\
			\hline
			\textbf{Std. Dev.} & 0.01491 & 0.01960 & 0.02611 & 0.02578 & 0.02429 \\
			\hline	
		\end{tabular}
	\end{center}
	\label{table:multi-cluster-results-random}
\end{table}

%TODO justify the results better
For both Spatial mode (Trial 1, 2, and 3) and Random Mode (Trial 4, 5, and 6), their average total activation values, $\overline{a}$, were similar. However, the variance is much greater for Random Mode. The level of variation may be attributed to the fact that the links connecting its CBLA Nodes were different at every trial.

On the other hand, for Spatial Mode, the average cluster activation values for Cluster 3 is larger than the other clusters. Cluster 3 is where the trigger took place in the experiment. While for Random Mode, the values of different clusters are relatively consistent. This shows that activations do tend to concentrate more around the origin of the trigger in Spatial Mode in contrast to Random Mode as we expected. 

The total activation and the cluster activations over time for Trial~2 (Spatial Mode) are shown in \Cref{fig:multi-cluster-results-spatial-2}. At the point at $t$ = 300s when the object was presented in front of a sensor in Cluster~3, the activation level at the cluster (red) shot up and the activation levels in the other three clusters trail after as we expected. Furthermore, it is interesting to point out that the magnitudes of activations for the other clusters are actually similar or even higher than Cluster 3. This means that CBLA Nodes in a cluster would respond to an event happening in a neighbouring cluster with similar level of intensity while the timing may be delayed.

\begin{figure} [!htb]
	\centering
	\includegraphics[width=1.0\textwidth]{"fig/validations/cbla_spatial_global_2015-11-16_14-33-11 - Metrics"}
	\caption[Average total activation and average cluster activations over time plots for Trial 2 (Spatial Mode) of the multi-cluster experiment]{Average total activation and average cluster activations for Trial 2 (Spatial Mode) of the multi-cluster experiment. In the Cluster Activation plot (bottom), the blue line represents Cluster 1; the green line represents Cluster 2; the red line represents Cluster 3; and the cyan line represents Cluster 4.}
	\label{fig:multi-cluster-results-spatial-2}
\end{figure}

In contrast, in the total activation and the cluster activations over time plots for Trial~5 (Random Mode) shown in \Cref{fig:multi-cluster-results-random-2}, the activation levels across different clusters are relatively even and without much delays. This is also expected since the CBLA Nodes are linked randomly, there is no expectation that CBLA Nodes in one cluster should activate earlier than another.

\begin{figure} [!htb]
	\centering
	\includegraphics[width=1.0\textwidth]{"fig/validations/cbla_random_2015-11-16_15-14-04 - Metrics"}
	\caption[Average total activation and average cluster activations over time plots for Trial 5 (Random Mode) of the multi-cluster experiment]{Average total activation and average cluster activations over time plots for Trial 5 (Random Mode) of the multi-cluster experiment. In the Cluster Activation plot (bottom), the blue line represents Cluster 1; the green line represents Cluster 2; the red line represents Cluster 3; and the cyan line represents Cluster 4.}
	\label{fig:multi-cluster-results-random-2}
\end{figure}

\subsection{Discussion}

In this experiment, we showed that the activations in response to a triggering event are more likely to begin and concentrate near the source of the trigger when the network is configured as Spatial Mode. Since we hypothesize that the users would find activations in close proximity to be more relevant and interesting, Spatial Mode seems to be a more promising network configuration. Therefore, in the User Study described in \Cref{sec:user-study}, the CBLA system was configured in Spatial Mode. 

Another observation made in the experiment was that there seems to be some periodic spontaneous activations for either network configuration. For example, in both \Cref{fig:multi-cluster-results-spatial-2,fig:multi-cluster-results-random-2}, there were activation at around 100s to 200s points, even though there was not any external interference. In fact, over a longer period of time, a self activation pattern becomes evident as shown in \Cref{fig:multi-cluster experiment cyclic activation} where the system was run in Spatial mode for 4500s uninterrupted. The CBLA Nodes activated spontaneously at a relatively consistent rate despite the absence of any external triggering events. 

\begin{figure} [!htb]
	\centering
	\includegraphics[width=1.0\textwidth]{"fig/validations/multi-cluster experiment cyclic activation"}
	\caption[Periodic spontaneous activation over a period of 4500s]{The CBLA system was running uninterrupted for 4500s in Spatial Mode. Even without any external events, the CBLA Nodes activated at a relatively consistent rate.}
	\label{fig:multi-cluster experiment cyclic activation}
\end{figure}

As mentioned in \Cref{sec:action_selection}, this periodic activation pattern is caused by the way which the relative action value, $\widehat{q^2_z}$, is calculated. Looking back at 
\Cref{eqn:relative_action_val}, \[\widehat{q^2_z} = \frac{q_t^2}{max(\overline{q^2_z}, \nu)}\] we can see that when the average squared action value, $\overline{q^2_z}$, hovers close to 0 for a long time, relative action value, $\widehat{q^2_z}$, would become very large. Fundamentally, this pattern is caused by the system's sensitivity to ambient sensor noise and can be adjusted by changing the sensitivity constant, $\nu$. Although setting $\nu$ to a larger value can eliminate this periodic activation pattern, it would also make the sculpture less responsive to the users and to the external environment. In addition, we believe that this kind of patterns can indeed be an interesting aspect of the behaviours of this interactive art sculpture. 


\section{User Study}\label{sec:user-study}

The CBLA system is designed to automatically generate interactive behaviours on interactive art sculptures. This user study aimed to determine whether the behaviours generated through this method can make the experience of interacting with the sculpture more interesting, compared with prescripted behaviours.

In this study, the test subjects reported their levels of interest at several points in time as they interacted with sculpture, which had two versions of behaviours. Afterwards, a short exit questionnaire was given to assess the subjects' overall experience. The results of this study enables designers to design more engaging and interesting interactive art sculptures. 

\subsection{Objectives}\label{sec:user-study-objectives}

This study aimed to investigate the users' responses to the behaviour of the CBLA system in an interactive art sculpture under different configurations. In addition, the relationships between the intensities and types of activations and users' level of interest as they interact with the sculpture were examined.

The user study aimed to answer the following three questions.

\begin{enumerate}
	\item Does the use of the CBLA increase user's interest level over prescripted behaviours?\label{itm:research-q1}
	\item Do people perceive CBLA as non-random?\label{itm:research-q2}
	\item Are certain behaviours  more interesting than others?\label{itm:research-q3}
\end{enumerate}


\subsubsection{Hypotheses}

Prior to the user study, an hypothesis was made for each of the research questions raised.

\begin{enumerate}
	\item The CBLA works by continuously generating new behaviours in order to improve its internal mathematical model of the sculpture and its sensed environment. The behaviours are adaptive and analogous to how animals and human beings learn. The users will find this kind of behaviour more interesting than prescripted behaviours.
	\item Although the CBLA continuously generates new behaviours, it is not random. the users will not perceive the CBLA-generated behaviours as random. 
	\item The users categorize some types of behaviours as being more interesting than others. 
\end{enumerate}

\subsection{Set-up}

The multi-cluster test bed described in \Cref{sec:multi-cluster-test-bed} was used in this user study as the interactive art sculpture that the participants interact with. In addition, the floor was lined with a grid numbered from 1 to 12 as shown in \Cref{fig:cbla-test-bed gird photo}. This grid allowed the participants to specify their locations within the sculpture.  

\begin{figure} [!htbp]
	\centering
	\includegraphics[width=0.8\textwidth]{"fig/validations/cbla-test-bed gird photo"}
	\caption[Photograph of the floor grid underneath the multi-cluster test bed]{Photograph of the floor grid underneath the multi-cluster test bed.}
	\label{fig:cbla-test-bed gird photo}
\end{figure}

In addition, a screen was set up next to sculpture to display the sample number. A laptop running the software was set up facing away from the sculpture beside the screen. 


\subsection{Recruitment}

Participants were recruited from the researchers' contact lists. All participants were healthy, physically able adults within the age range of 18 to 65 years old, male and female. Potential participants who were blind were excluded because they would be unable to perceive many of the behaviours, which were visually-manifested. Potential participants who were wheelchair users were excluded because they would not be able to access the studio, which had no elevator access.

In addition, participants had little prior knowledge about that the workings of the CBLA system to avoid the subject-expectancy effect. This is a form of bias in which the test subject expects a particular result and this unconsciously affects the outcome. 

\subsection{Procedures}\label{sec:user-study-procedure}

Each participant was provided with the same information about the procedures of this user study. Only one participant was interacting with the sculpture at a time. 

\subsubsection{Before the Trial}

The test participant was invited to interact with an interactive art sculpture installed in the Toronto studio of Philip Beesley Architect Inc. (PBAI). The participant was then informed about the procedures of the study as described in the Information and Consent Form (\Cref{Append:User Study Materials info-form}) and was asked to sign the attached consent form before he or she began participating in the trial. 

After that, the participant was given a pen and an envelope with a stack of 8 identical business-card-sized questionnaire cards shown in \Cref{fig:Questionaire-Card2}. He or she was asked to fill out one card every time a long tone was heard. The first question on the card asks the subject to write down the current sample number as shown on the screen. The second asks for his or her subjective interest level regarding the behaviour of the sculpture at that moment. The third question asks the subject to mark his or her location at that moment by looking down on to the grid on the floor. He or she was told to make a mark between the boxes if he or she was standing in between those boxes. 

\begin{figure} [!htb]
	\centering
	\fbox{\includegraphics[height=0.55\textheight]{"fig/validations/Questionaire-Card2"}}
	\caption[Questionnaire card for the user study]{Questionnaire card for the user study.}
	\label{fig:Questionaire-Card2}
\end{figure}

Right before the start of the trial, the researcher ran through the study procedures with the participant one last time. The participant was told that he or she was free to walk around the space and interact with the art sculpture in any way and that there were not any prescribed interactions. The subject was also told that the entire trial would last for 20 minutes and he or she may request to terminate the study at any time.


\subsubsection{During the trial}

The test participant was free to roam around the space and interact with the art sculpture. A distinct long tone went off periodically at a 2.5 minutes interval. Each time the tone went off, the participant would take out an empty questionnaire card, and answer the questions on the card. The trial would go on for 20 minutes which was equivalent to 8 cards.

There were two versions of interactive behaviours: Prescripted Mode and CBLA Mode. The Prescripted Mode was powered by the Prescripted Engine and is described in \Cref{sec:prescripted-behaviours}. The CBLA Mode was powered by the CBLA Engine and is described in detail in \Cref{chap:cbla}. The participants were not informed about the versions of the behaviours that they were interacting with nor the fact that there were two different versions of interactive behaviours. Both versions of the behaviours were run for approximately the same amount of time. After the fourth tone (which was half-way through the trial), the researcher would switch to the other version manually after the participant had finished filling in the questionnaire card and resumed interacting with the sculpture. 

Since the experience of interacting with the sculpture was new to the test subjects, the order that the two types of behaviours was presented can make a big difference. The subjects may simply find the novelty of interacting with the sculpture interesting irrespective of the type of behaviour. In addition, since the exit questionnaires were given after the trials, the behaviours that the subjects experienced near the end of the trials may have more profound effects than the ones that they experienced earlier in the trials. Therefore, half of the participants were exposed to Prescripted Mode first and the other half were exposed to CBLA Mode first.

\subsubsection{After the trial}

After a participant had filled out the eighth questionnaire card, he or she was informed that the trial was completed. He or she then returned the questionnaire cards in the envelope given to him or her prior to the trial. The participant then filled out an exit questionnaire, shown in \Cref{Append:User Study Materials exit-survey}, which has the following five questions.

\begin{enumerate}
	\item How interesting was your overall experience while interacting with the art 
	sculpture? \label{itm:survey-q1}
	\item How responsive was the sculpture to your presence?  Do you think its behaviour was totally random, or do you think it was responding directly to you? \label{itm:survey-q2}
	\item How familiar are you with machine learning algorithms? \label{itm:survey-q3}
	\item How would you describe the behaviour of the sculpture? \label{itm:survey-q4}
	\item Additional comments \label{itm:survey-q5}
\end{enumerate}

Question~\ref{itm:survey-q1} elicits the participant's general opinions about how interesting it was interacting with the sculpture. Question~\ref{itm:survey-q2} can provide insights on research question~\ref{itm:research-q2}. Both questions~\ref{itm:survey-q1}~and~\ref{itm:survey-q2} were rated on a scale from 0 to 9. Question~\ref{itm:survey-q3} allows us to gauge whether or not the participant's prior exposure to machine learning had any effect of his or her perceptions of the behaviours of sculpture and it was rated on a scale from 0 to 4. Questions~\ref{itm:survey-q4}~and~\ref{itm:survey-q5} are open-ended questions that can give us some qualitative information about the participant's experience that we might not capture otherwise.

After that, the participant was provided with the debriefing letter shown in \Cref{Append:User Study Materials debriefing}, which has more information about the learning algorithm, the interactive behaviours, and the purpose of this study. In addition, the interactive behaviours that he or she interacted with were explained verbally after all questionnaires were collected.

\subsection{Results and Data}

A total of 10 participants were recruited. There were three main sets of data collected in each trial: the set of 8 questionnaire cards, the exit questionnaire, and the states of the CBLA system during the entire trial.

The questionnaire cards recorded each subject's levels of interest and locations at the 8 sample points. The levels of interest data enabled us to compute the subject's overall interest level in each of the two segments, Prescripted Mode and CBLA Mode. We further separated the data into two groups based on the trial started with Prescripted Mode first or CBLA Mode first and they are presented in \Cref{table:user-study-cards-results-prescripted-first,table:user-study-cards-results-cbla-first}. On the other hand, the location data enabled us to examine the relationships between the activations near the test subject to his or her reported interest level.

\begin{table}[!htb]
	\caption[Self-reported interest levels for Prescripted-first trials in the user study]{Self-reported interest levels at the sample points collected during Prescripted-first trials in the user study}
	\begin{center}
		\begin{tabularx}{0.75\textwidth}{ | c | *{8}{>{\centering\arraybackslash}X|}}
			% Headers
			\hline
			\multirow{2}{*}{\textbf{Trial \#} } & \multicolumn{8}{c|}{\textbf{Sample Interest Level}} \\ 
			\cline{2-9}
			& \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} 
			& \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8} \\ 
			\hline\hline
			% Data
			1 & 6 &	4 &	6 & 3 & 7 & 6 & 4 & 7 \\ \hline
			3 & 1 & 4 & 2 & 3 & 5 & 3 & 3 & 2 \\ \hline
			5 & 4 & 4 & 5 & 5 & 3 & 3 & 5 & 4 \\ \hline
			7 & 7 & 6 & 7 & 5 & 5 & 6 & 5 & 6.5 \\ \hline
			10 & 9 & 9 & 7 & 5 & 5 & 3 & 3 & 2 \\ \hline
		\end{tabularx}
	\end{center}
	\label{table:user-study-cards-results-prescripted-first}
\end{table}
\begin{table}[!htb]
	\caption[Self-reported interest levels for CBLA-first trials in the user study]{Self-reported interest levels at the sample points collected during CBLA-first trials in the user study}
	\begin{center}
		\begin{tabularx}{0.75\textwidth}{ | c | *{8}{>{\centering\arraybackslash}X|}}
			% Headers
			\hline
			\multirow{2}{*}{\textbf{Trial \#} } & \multicolumn{8}{c|}{\textbf{Sample Interest Level}} \\ 
			\cline{2-9}
			& \textbf{1} & \textbf{2} & \textbf{3} & \textbf{4} 
			& \textbf{5} & \textbf{6} & \textbf{7} & \textbf{8} \\ 
			\hline\hline
			% Data
			2 & 8 &	7 &	6 & 7 & 7 & 6 & 8 & 6 \\ \hline
			4 & 0 & 4 & 6 & 9 & 7 & 9 & 2 & 0 \\ \hline
			6 & 5 & 5 & 5 & 5 & 2 & 2 & 1 & 1 \\ \hline
			8 & 8 & 3 & 6 & 8 & 5 & 3 & 2 & 6 \\ \hline
			9 & 5 & 8 & 8 & 7 & 7 & 7 & 4 & 5 \\ \hline
		\end{tabularx}
	\end{center}
	\label{table:user-study-cards-results-cbla-first}
\end{table}

The exit questionnaires provided information about the participants and their overall opinions and thoughts on their experience before any additional information about the user study was revealed. In addition, observations of the participants' behaviours and interesting comments made in verbal conversations with were noted to provide further insights.

The input, output, and internal variables of the CBLA Nodes and non-CBLA Nodes during the entire trial were collected. The activation levels of each CBLA Node were extracted at 1.0s time intervals for analyzing the correlations between activations and interest levels. A time interval of 1.0s was chosen to give sufficient granularity to the data. Other similar values could have been chosen and it would not affect the results of the analysis significantly.


\newcounter{analysis-id} \stepcounter{analysis-id}
\subsection{Analysis~\Roman{analysis-id} -- Average Interest Levels between Prescripted Mode and CBLA Mode} \label{sec:user-study-analysis-interest}
\stepcounter{analysis-id}

We first separated the levels of interest data on the questionnaire cards (\Cref{table:user-study-cards-results-prescripted-first,table:user-study-cards-results-cbla-first}) into four groups: Prescripted Mode (first half),  Prescripted Mode (second half),  CBLA Mode (first half), and CBLA Mode (second half). The ``Prescripted Mode'' or ``CBLA Mode'' indicates the version of the behaviours that was running when the samples were recorded, and ``(first half)'' or ``(second half)'' indicates whether the samples were taken during the first or the second half of the trial. We then took the average across all trials for each sample point, which resulted in four sets of data with five elements each.

\begin{tabular}{l l}
	Prescripted Mode (first half):      &(4.75, 2.5, 4.5, 6.25, 7.5) \\
	Prescripted Mode (second half):     &(7.0, 4.75, 5.0, 6.25, 7.0) \\
	CBLA Mode (first half):             &(6.75, 4.5, 1.5, 4.0, 5.75) \\
	CBLA Mode (second half):            &(6.0, 3.25, 3.75, 5.625, 3.25)	
\end{tabular}

We then performed Welch's T-Tests for unequal variance on different combinations of these four sets of data as described below. For each test from Test~\ref{itm:interest-wtest-first} to Test~\ref{itm:interest-wtest-last}, the two-tails P-value must be below 0.1 in order for the null hypothesis (H0) to be rejected in favour of the alternate hypothesis (H1).

\begin{enumerate}
	\item Prescripted Mode: on during first half vs one during second half \label{itm:interest-wtest-first}
		\begin{itemize}[align=left]
			\item[Data Set 1: ] Prescripted Mode (first half)
			\item[Data Set 2: ] Prescripted Mode (second half)
			\begin{itemize}
				\item[--- H0.] Average interest level for prescripted mode is the same regardless if it is on first or second.
				\item[--- H1.] Average interest level for prescripted mode is different depending on whether it is on first or second.
			\end{itemize}
		\end{itemize}
	\item CBLA Mode: on during first half vs one during second half
		\begin{itemize}[align=left]
			\item[Data Set 1: ] CBLA Mode (first half)
			\item[Data Set 2: ] CBLA Mode (second half)
			\begin{itemize}
				\item[--- H0.] Average interest level for CBLA mode is the same regardless if it is on first or second.
				\item[--- H1.] Average interest level for CBLA mode is different depending on whether it is on first or second.			
			\end{itemize}
		\end{itemize}
	\item Either Mode: on during first half vs one during second half
		\begin{itemize}[align=left]
			\item[Data Set 1: ] Prescripted Mode (first half) + CBLA Mode (first half)
			\item[Data Set 2: ] Prescripted Mode (second half) + CBLA Mode (second half)
			\begin{itemize}
				\item[--- H0.] Average interest level is the same regardless if it is on first or second.
				\item[--- H1.] Average interest level is different depending on whether it is on first or second.
			\end{itemize}
		\end{itemize}
	\item CBLA Mode vs. Prescripted Mode: on during first half
		\begin{itemize}[align=left]
			\item[Data Set 1: ] CBLA Mode (first half)
			\item[Data Set 2: ]  Prescripted Mode (first half)
			\begin{itemize}
				\item[--- H0.] Average interest level for CBLA mode is the same as Prescripted mode when it is on first.
				\item[--- H1.] Average interest level for CBLA mode is different from Prescripted mode when it is on first.
			\end{itemize}
		\end{itemize}
	\item CBLA Mode vs. Prescripted Mode: on during second half\label{itm:w-ttest-cbla-2nd}		\begin{itemize}[align=left]
			\item[Data Set 1: ] CBLA Mode (Second half)
			\item[Data Set 2: ] Prescripted Mode (second half)
			\begin{itemize}
				\item[--- H0.] Average interest level for CBLA mode is the same as Prescripted mode when it is on second.
				\item[--- H1.] Average interest level for CBLA mode is different from Prescripted mode when it is on second.
			\end{itemize}
		\end{itemize}
	\item CBLA Mode vs. Prescripted Mode: on during either half \label{itm:interest-wtest-last}
		\begin{itemize}[align=left]
			\item[Data Set 1: ] CBLA Mode (first half) + CBLA Mode (second half)
			\item[Data Set 2: ] Prescripted Mode (first half) + Prescripted Mode (second half)
			\begin{itemize}
				\item[--- H0.] Average interest level for CBLA mode is the same as Prescripted mode.
				\item[--- H1.] Average interest level for CBLA mode is different from Prescripted mode.
			\end{itemize}
		\end{itemize}
\end{enumerate}


Out of the six Welch's T-Tests, only Test~\ref{itm:w-ttest-cbla-2nd}, which compared the levels of interest between CBLA Mode and Prescripted Mode when they were on during the second half of the trial, was able to reject the null hypothesis with a two-tailed P-value of 0.0684. The average interest level of Prescripted Mode and CBLA Mode were 6.0 and 4.375 respectively. This means that Prescripted Mode was more interesting than CBLA Mode by approximately 37\% when they were on during the second half of the trial with a 96.58\% confidence. We did not find any significant differences in reported levels of interest between CBLA Mode and Prescripted Mode in any other cases.

Furthermore, we were interested in finding out if an average participant would find Prescripted Mode more or less interesting than CBLA Mode. Since each participant had seen both versions of behaviours, we compared their responses by performing Paired T-Tests. 

We first compared each test subject's average levels of interests in CBLA Mode and Prescripted Mode, irrespective of which halves the behaviours were presented. 
\begin{enumerate}[resume]
 	\item CBLA Mode vs Prescripted Mode
 	\begin{itemize}[align=left]\label{itm:paired-ttest-both-halves}
 		\item[Data Set 1: ]  CBLA Mode (first half) + CBLA Mode (second half)
 		\item[Data Set 2: ]  Prescripted Mode (second half) + Prescripted Mode (first half) 
 		\begin{itemize}
 			\item[--- H0.] Participants find that CBLA Mode is equally as interesting as Prescripted Mode.
 			\item[--- H1.] Participants find that CBLA Mode is not equally as interesting as the Prescripted Mode.
 		\end{itemize}
 	\end{itemize}
\end{enumerate}

In Test~\ref{itm:paired-ttest-both-halves}, we found that CBLA Mode was in fact less interesting than Prescripted Mode with a 96.16\% confidence. An average participant who had interacted with both kinds of behaviours gave Prescripted Mode a rate of 5.55 and a CBLA Mode a rate of 4.44. This means that Prescripted mode was approximately 25\% more interesting than CBLA Mode irrespective of the order that they were presented. 

Taking a closer look, we wanted to see if the orders that the two versions were presented had any significance. 

\begin{enumerate}[resume]
	\item CBLA Mode vs. Prescripted Mode when Prescripted Mode is on first
	\begin{itemize}[align=left]\label{itm:paired-ttest-first-half}
		\item[Data Set 1: ] CBLA Mode (second half)
		\item[Data Set 2: ] Prescripted Mode (first half)
		\begin{itemize}
			\item[--- H0.] Participants find that CBLA Mode is equally as interesting as Prescripted Mode when Prescripted Mode is on first.
			\item[--- H1.] Participants find that CBLA Mode is not equally as interesting as the Prescripted Mode when Prescripted Mode is on first.
		\end{itemize}
	\end{itemize}
	\item CBLA Mode vs Prescripted Mode when CBLA Mode is on first
	\begin{itemize}[align=left]\label{itm:paired-ttest-second-half}
		\item[Data Set 1: ]  CBLA Mode (first half) 
		\item[Data Set 2: ]  Prescripted Mode (second half) 
		\begin{itemize}
			\item[--- H0.] Participants find that CBLA Mode is equally as interesting as Prescripted Mode when CBLA Mode is on first.
			\item[--- H1.] Participants find that CBLA Mode is not equally as interesting as the Prescripted Mode when CBLA Mode is on first.
		\end{itemize}
	\end{itemize}
\end{enumerate}

In Test~\ref{itm:paired-ttest-first-half}, we could not find any significance difference in ratings between CBLA Mode and Prescripted Mode when Prescripted Mode was on first. On the other hand, in Test~\ref{itm:paired-ttest-second-half}, we found that CBLA Mode was rated lower at an average of 4.5 compared to Prescripted Mode at an average of 6.0 with a 96.32\% confidence when CBLA Mode was on first. This translates to a 33\% increase in interest level when the behaviour was switched from CBLA Mode to Prescripted Mode. This is quite surprising as we expected the initial curiosity of the participants would boost the interest level of the behaviour presented first.


\subsection{Analysis~\Roman{analysis-id} -- Correlations between Activation level and Interest Level} \label{sec:user-study-analysis-activations}
\stepcounter{analysis-id}

This analysis aims to determine if there were any correlations between the participants' reported levels of interest to the activation levels of the sculpture. In this analysis, we did not consider which version of the behaviours was running at the sample point and focused on the actual activation levels of the sculpture.

The extracted activation levels for each CBLA Node were the output levels of each node averaged over 1.0s windows. For each trial, there were 8 sample points which correspond to the times when the participant filled out questionnaire cards and reported his or her levels of interest and locations. For each sample point, the time interval containing it and 30 time intervals (which translates to 30 seconds) preceding it were considered as activations related to the sample point. A time interval of 30s was chosen in order to include prior activations that were likely to be associated with the participant's response at that a sample point. 

Two metrics were developed to quantify activation levels. The first metric is ``average sample average activation'',  $\overline{\overline{\alpha}}$. It is computed by taking the average of the output values in the 30 time intervals preceding and at the sample point and then taking the average of that value across all the Nodes under consideration as formulated in \eqref{eqn:bar_bar_alpha}.

\begin{equation}\label{eqn:bar_bar_alpha}
	\overline{\overline{\alpha}} = \frac{1}{N}\sum_{j=0}^{N}\frac{1}{31}\sum_{t=t_{s-30}}^{t_{s}}\overline{m}_{jt}
\end{equation}
where $\overline{\overline{\alpha}}$ is the average sample average activation level among all CBLA Nodes being considered; $N$ is the number of CBLA Nodes being considered; $t_s$ is the time interval that the sample point is in. $t_{s-30}$ is the time interval that is 30 time intervals before $t_s$; and $\overline{m}_{jt}$ is the output level of CBLA Node $j$ at time interval $t$. 

The second metric is the ``average sample peak activation'', $\overline{\widehat{\alpha}}$. It is computed by taking the maximum output values in the 30 time intervals preceding and at the sample point and then taking the average of that value across all the nodes under consideration as formulated in \eqref{eqn:bar_hat_alpha}.

\begin{equation}\label{eqn:bar_hat_alpha}
\overline{\widehat{\alpha}} = \frac{1}{N}\sum_{j=0}^{N} \text{max}(\overline{m}_{jt_{s-30}}, ... , \overline{m}_{jt_{s}})
\end{equation}
where $\overline{\widehat{\alpha}}$ is the average sample peak activation level among all CBLA Nodes being considered; $N$ is the number of CBLA Nodes being considered; $\overline{m}_{jt_{s-30}}$ and $\overline{m}_{jt_s}$ are the output levels of the CBLA Node $j$ at time intervals $t_{s-30}$ and $t_s$ respectively.

Using those two metrics, we examined if there were any correlations between interest levels and different types of activation levels. One type of activation level is the system wide activation which was captured by computing the metrics among all CBLA Nodes. The other type is device type activation, which was captured by computing the metrics among just Half-Fin Nodes, Light Nodes, or Reflex Nodes. 
%TODO provide rational for the metrics

In addition, proximities of the activations to the participant were considered. We formulated a modified version of $\overline{\overline{\alpha}}$ and $\overline{\widehat{\alpha}}$ that are weighted by the inverse proximities of the Nodes to the participant. They are called ``average sample proximal average activation'', $\overline{\overline{\rho}}$, and ``average sample proximal peak activation'',  $\overline{\widehat{\rho}}$. The proximity was measured in relative distance unit as only the relative proximities among Nodes were considered in this metric. 

\begin{equation}\label{eqn:bar_bar_rho}
\overline{\overline{\rho}} = \frac{1}{N}\sum_{j=0}^{N} \frac{1}{31 \cdot d_j} \sum_{t=t_{s-30}}^{t_{s}}\overline{m}_{jt}
\end{equation}
where $\overline{\overline{\rho}}$ is the average sample proximal average activation level among all CBLA Nodes being considered; $N$ is the number of CBLA Nodes being considered; $d_j$ is the relative distance between the CBLA Node $j$ and the subject; $t_s$ is the time interval that the sample point is in; $t_{s-30}$ is the time interval that is 30 time intervals before $t_s$; and $\overline{m}_{jt}$ is the output level of CBLA Node $j$ at time interval $t$. 

\begin{equation}\label{eqn:bar_hat_rho}
\overline{\widehat{\rho}} = \frac{1}{N}\sum_{j=0}^{N} \frac{1}{d_j} \text{max}(\overline{m}_{jt_{s-30}}, ... , \overline{m}_{jt_{s}})
\end{equation}
where $\overline{\widehat{\rho}}$ is the average sample proximal peak activation level among all CBLA Nodes being considered; $N$ is the number of CBLA Nodes being considered; $d_j$ is the relative distance between the CBLA Node $j$ and the subject; $\overline{m}_{jt_{s-30}}$ and $\overline{m}_{jt_{s}}$ are the output levels of the CBLA Node $j$ at time intervals $t_{s-30}$ and $t_s$ respectively.

Since we were interested in the correlations between activation levels of the sculpture and the interest level of an average user, we combined the data for all 10 trials and computed metrics described above. We then computed the Pearson correlation coefficients, $r$, between each of those metrics and the user's level of interest in \Cref{table:user-study-correlation-results}.

\begin{table}[!htb]
	\caption[Correlations between activation levels and user's interest level]{Correlations between activation levels and user's interest level}
	\begin{center}
		\begin{tabularx}{0.75\textwidth}{| c | l | *{2}{>{\centering\arraybackslash}X|}}
			% Headers
			\hline
			\textbf{Metric} &  \textbf{Nodes} & \boldmath{$r$} & \textbf{P-value} \\ 
			\hline\hline
			% Data
			$\overline{\overline{\alpha}_{all}}$ & all CBLA Nodes & 0.366304 & 0.000833 \\ \hline
			$\overline{\overline{\alpha}_{hf}}$  & Half-Fin Nodes  & 0.357302 & 0.001139 \\ \hline
			$\overline{\overline{\alpha}_{l}}$   & Light Nodes & 0.395201 & 0.000286 \\ \hline
			$\overline{\overline{\alpha}_{rfx}}$ & Reflex Nodes & -0.083434 & 0.461854 \\ \hline
			$\overline{\widehat{\alpha}_{all}}$  & all CBLA Nodes & 0.317221 & 0.004143 \\ \hline
			$\overline{\widehat{\alpha}_{hf}}$   & Half-Fin Nodes & 0.374608 & 0.000618 \\ \hline
			$\overline{\widehat{\alpha}_{l}}$    & Light Nodes & 0.322380 & 0.003541 \\ \hline
			$\overline{\widehat{\alpha}_{rfx}}$  & Reflex Nodes & 0.021213 & 0.851844 \\ \hline
			$\overline{\overline{\rho}_{all}}$   & all CBLA Nodes & 0.345267 & 0.001709 \\ \hline
			$\overline{\widehat{\rho}_{all}}$    & all CBLA Nodes & 0.317167 & 0.004149\\ \hline
		\end{tabularx}
	\end{center}
	\label{table:user-study-correlation-results}
\end{table}

Over the whole system, there was a weak positive correlation between interest level and both average sample average activation levels, $\overline{\overline{\alpha}_{all}}$, and average sample peak activation levels, $\overline{\widehat{\alpha}_{all}}$, with over 99\% confidence.

For device type correlation, we found a higher correlation for Light Nodes than the system-wide correlation when considering the average sample average activation levels. On the other hand, higher correlation was found for Half-Fin Nodes when considering the average sample peak activation levels. Interestingly, we did not find any significant correlation between the activation levels of Reflex Node to the user's interest level. 

The proximities of the activations do not increase the correlation. The correlation coefficients for average sample proximal average activation $\overline{\overline{\rho}_{all}}$ and average sample proximal peak activation $\overline{\widehat{\rho}_{all}}$ are approximately the same as their system-wide counterparts. This might be attributed to the fact that the sculpture is relatively small. 

Although the overall correlations across all ten studies were relatively weak, there were in fact large variations among different studies. For instance, the average total peak activations level, $\overline{\widehat{\alpha}_{all}}$, for Study 10 showed strong correlation with the subject's interest level. It had a Pearson coefficient, $r$, of 0.924443 with over 98\% confidence. On the other hand, the same metric for Study 3 showed no significant correlation. The two cases are plotted in \Cref{fig:correlation-study-specific} for a visual side-by-side comparison.


\begin{figure}[!htb]
	\centering
	\begin{subfigure}[t]{0.45\textwidth}
		\centering
		\includegraphics[width=1.0 \textwidth]{"fig/validations/study_10 - correlation total activation"}
		\caption[Study 10]{Study 10 with strong correlation}
		\label{fig:correlation-study10}
	\end{subfigure}
	~ 
	\begin{subfigure}[t]{0.45\textwidth}
		\centering
		\includegraphics[width=1.0 \textwidth]{"fig/validations/study_3 - correlation total activation"}
		\caption[Study 3]{Study 3 with no significant correlation}
		\label{fig:correlation-study3}
	\end{subfigure}
	\caption[Study-specific correlation between activation level and user's level of interest]{Study-specific correlation between the average sample peak activation level, $\overline{\widehat{\alpha}_{all}}$, and user's level of interest.}
	\label{fig:correlation-study-specific}
\end{figure}

This shows that different people responded and interacted very differently to the behaviours of the sculpture. For instance, some people might indeed be attracted by the activations and were engaged to interact with the sculpture, while some might be attracted to the sculpture due to other reasons, such as the aesthetic of the design. More samples would be needed to further categorize the different types of users. 


\FloatBarrier
\subsection{Analysis~\Roman{analysis-id} -- Responsiveness}\label{sec:user-study-analysis-responsiveness}
\stepcounter{analysis-id}

In the exit questionnaire, we asked the participants to rate their overall interest level and how responsive they thought the behaviour was. In \Cref{table:user-study-responsive-data}, responses for the two questions and the average interest level reported on the questionnaire cards were tabulated. All three ratings were reported on a scale of 0 to 9. 

\begin{table}[!htb]
	\caption[User reported overall interest levels and responsiveness]{User reported overall interest levels and responsiveness for each trial. The trials are further grouped into Prescripted First and CBLA First.}
	\begin{center}
		\def\tabularxcolumn#1{m{#1}}
		\begin{tabularx}{1.0\textwidth}{ r | c |*{3}{>{\centering\arraybackslash}X|}}
			% Headers
			\cline{2-5}
			& \textbf{Trial \#} &  \textbf{Q1. Overall Interest Level} & \textbf{Q2. Responsiveness}
			& \textbf{Average Interest Level on Questionnaire Cards} \\ 
			\hhline{~====}
			% Data
			\textbf{Prescripted First} 
			& 1 & 6 & 4 & 5.375 \\ \cline{1-5}
			& 3 & 6 & 5 & 2.875 \\ \cline{2-5}
			& 5 & 6 & 6 & 4.125\\ \cline{2-5}
			& 7 & 7 & 6 & 5.938 \\ \cline{2-5}
			& 10 & 9 & 7 & 5.375 \\ \cline{2-5}
			\textbf{CBLA First} 
			& 2 & 8 & 8  & 6.875 \\ \cline{1-5}
			& 4 & 7 & 4.5 & 4.625  \\ \cline{2-5}
			& 6 & 6 & 6 & 3.250 \\ \cline{2-5}
			& 8 & 7 & 7 & 5.125 \\ \cline{2-5}
			& 9 & 8 & 9 & 6.375 \\ \cline{2-5}		
		\end{tabularx}
	\end{center}
	\label{table:user-study-responsive-data}
\end{table}

The Pearson correlation coefficient, $r$, between responsiveness and overall interest level was 0.680 with over 96\% confidence. Similarly, the $r$ between responsiveness and the average interest level reported on the questionnaire cards was 0.572 with over 91\% confidence. This shows that responsiveness of the behaviours did have a moderate positive correlation to how interesting they were to the users.

On the other hand, there was moderate discrepancy between the overall interest level and the average interest level reported on the questionnaire cards. Taking the difference between the two revealed that, on average, the overall interest level rating was greater than average interest level reported on the questionnaire cards by 2.01 points. Their Pearson correlation coefficient is 0.682 with over 97\% confidence. These results show that the participants' reported interest levels as they were interacting with the sculpture were significantly different from the ones reported afterwards. This is probably because some people tended to put more emphasis on their most recent experience when answering the questions on the exit questionnaires. In fact, if Prescripted Mode was on during the second half of the trials, the average responsiveness rating was 6.9 as opposed to 5.6 when CBLA Mode was on during the second half with confidence level over 89\%. Since the CBLA Mode should be less responsive than Prescripted Mode, we can speculate that when subjects reported on the their impressions on the responsiveness of the sculpture after the trials, they disproportionately emphasized their most recent interactions.



\subsection{Discussion}

In this user study, we attempted to answer the three research questions raised in \Cref{sec:user-study-objectives}. 

First,  does the use of the CBLA increase user's interest level over prescripted behaviours?  In the analyses done in \Cref{sec:user-study-analysis-interest}, we showed that CBLA Mode was in fact less interesting than Prescripted Mode by 25\%. This effect was even more pronounced when the trial started with CBLA Mode first and switched to Prescripted Mode halfway. Prescripted Mode was on average 33\% more interesting that CBLA Mode. This is contrary to our hypothesis as we did not find any significant evidence that the use of CBLA increased the users' interest levels.
%TODO add more discussion about why we got the hyptohesis wrong 

Second, do people perceive CBLA as non-random? It is more difficult to answer this question since we did not ask the participants to rate the sculpture's responsiveness for each type of behaviour. In fact, based on question~\ref{itm:survey-q4} of the exit questionnaire, most participants did not realize that there were two distinct sets of behaviours that were switched over midway. This wasn't asked since we couldn't reveal the type of behaviours that they should expect during the trials. However, we did find a positive correlation between interest level and responsiveness rating. Since CBLA Mode was considered less interesting when we tried to answer research question~\ref{itm:research-q1},  this might indicate that CBLA Mode was considered less responsive. In addition, we speculate that test subjects would emphasize the later half of the trials when answering the exit questionnaires. On that front, we also found that the responsiveness ratings were lower when CBLA Mode was on in the second half. In addition, the written responses when the participants were asked to described the behaviours of the sculpture, they often described the CBLA portion using words like ``random'', ''totally random'', ``somewhat random'', or ``unresponsive''. This shows that many participants did think that CBLA Mode was indeed random. This is also contrary to our hypothesis that the participants can perceive the learning behaviours as non-random.

Finally, are certain behaviours more interesting than others? In the analysis done in \Cref{sec:user-study-analysis-activations}, we found that there was a weak positive correlation between the overall activation levels and the user's interest level. In other word, the participants found that more actuation is more interesting than less actuation. On the other hand, we did not find that any specific device had a significantly stronger positive correlation. However, we found that activations of a Reflex Node, which actuates either a pair of LEDs or a vibration motor, shows no correlation with the user's interest level. Similarly, we did not find that proximity of the actuations influenced the user's level of interest much either. This may be because the size of the sculpture was relatively small and the participants could easily see, hear, and walk to anywhere in the space relatively quickly, in comparison to the time required to fill out the questionnaire cards. In sum, we show that activations do tend to increase user's level of interest but, contrary to our hypothesis, we could not find any particular categories of behaviours that were more interesting than the others. 

However, these conclusions may only apply to this particular set-up under this particular set of procedures. For instance, we hypothesize that, over a long period of time, prescripted behaviour would become repetitive and less interesting. In this user study, the participants were only interacting with the prescripted behaviours for 10 minutes and perhaps that was insufficient for them to realize that it was repetitive and lose interest. In fact, one participant thought it was responsive to sound, and was making noise and still trying to figure out its non-existent response to sound until the end. 

Moreover, the set up of this interactive art sculpture was also very different from a typical set-up. Typically, this kind  of sculpture is set up as an art exhibition in some kinds of public space like department stores, office buildings, and museums. Visitors are free to enter or leave the space as they like. In cases of a permanent installation, the sculpture is placed in the background to some other daily activities. This is very different from the one-on-one, timed interactions that we tested in this user study. In addition, typically, visitors would be accompanied by other people and the effect of multiple occupants in the same space was not covered. 

In addition, this project is motivated by the desire to generate life-like behaviours automatically. We don't know if being life-like is interesting to all people. In fact, from the informal conversations after the studies, we realized that people had very different interests, and different expectations about the behaviours of the sculpture. Some expected much more coordinated, fast-pace movements, while some found the slow and organic-looking movements appealing. Some expected the sculpture to be very responsive, while some did not even know that there were sensors that could detect their presence at first. Some participants took figuring out the exact mechanism of sculpture's behaviours as a challenge; some were enjoying it and some were frustrated by their abilities to figure out the patterns. Moreover, there were also participants who enjoyed looking at the design of the sculpture and some were interested in the design of the circuit boards and actuators. They spent a great deal of time examining the details of the sculpture itself rather than interacting with the sculpture.

Furthermore, the ways how the participants interacted with the sculpture varied greatly. Some mainly stood back and observed, while some walked around the space rapidly and touched many parts of the sculpture at great frequency and perhaps randomly. In fact, one participant was taking apart the sculpture in order to better examine the parts and how those alterations change the activation patterns of the sculpture. 

This shows that the data should be further categorized based on the type of user. Different people expected different things out of this experience, and analyzing the different groups separately may reveal more useful information about user's response to the different types of behaviours. In addition, the user study should be done in a more realistic setting over a longer period of time to reveal whether CBLA can indeed be more interesting in the long run.

