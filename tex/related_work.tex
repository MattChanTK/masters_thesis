\chapter[Related Work]{Related Work\footnote{Part of this chapter is adapted from paper published in IROS~2015~\cite{Chan2015}}} 
 \label{chap:related_work}

% An intro paragraph laying out the contents of this chapter
In this chapter, related work in interactive arts are first presented in order to provide a context for this work. Then, previous research on artificial life and developmental robotics, which provide the inspirations and the foundations for our approaches, are explored. Lastly, the Intrinsic Motivation Curiosity (IAC)~\cite{Oudeyer2007}, which forms the basis of the Curiosity-Based Learning Algorithm (CBLA), is dissected and discussed in detail.

\section{Interactive Arts}
Interactive arts can be categorized as Static, Dynamic-Passive, Dynamic-Interactive, and Dynamic-Interactive (varying) based on the degree of the interaction between the art works and the viewers~\cite{Edmonds2004}. Dynamic-Interactive systems give the human viewers an active role in defining the behaviours of the system. This category introduces an agent that modifies the specifications of the art object. This additional unpredictability introduces a new dimension of complexity to the behaviours of the system. 

In~\cite{Drummond2009}, Drummond examined the conceptual elements of interactive musical arts. For an interactive system to move beyond being simply a complex musical instrument with a direct reactive mapping from inputs to generation of sound, it must possess some level of autonomy in the composition and generation of music. In addition, the interactivity should be bilateral; the performer influences the music and the music influences the performer. 

These concepts can easily be extended to visual and kinetic arts. To begin, to enable bilateral influences, user engagement becomes an important aspect of interactive arts. There needs to be an \textit{attractor} that captures the user's attention, a \textit{sustainer} that keeps the user engaged, and a \textit{relater} that fosters relationship between the users and artworks~\cite{Edmonds2006}. 

%Description of Variations. 
Variations~\cite{Wands2005}, which is an audio-based sculptural systems, engages the users by allowing them to influence the sounds that they hear by placing a few balls onto its vertical tubes in different ways. Although the users play an active role in mixing the music, the sculpture remains autonomous in its sound production. Relationship between the artwork and the users is developed when the sounds generated by the sculpture influence the ways that the users arrange those balls. 
%Description of Iamascope
Likewise, the Iamascope in Beta\_space~\cite{Costello2005} engages the users by capturing the participant's movements using a camera and generating different projected kaleidoscopic images and musical notes depending on the speeds and frequencies of those movements. In addition, the users' perceptions about the working of the system play a critical role in defining the nature of their relationship with the artworks. For instance, some subjects in the Iamascope experiment reported that they felt that the artwork was in fact controlling them. 

Works in interactive architecture~\cite{Hangar.org}\cite{Fox2009} try to provide a responsive and immersive environment where the viewers can feel as if they belong to the system. For instance, the ADA by Sedus is a room enclosed by 2.6m tall mirrors with responsive illuminated colour tiles covering the entire floor. The colour of these tiles changes depending on the occupants. In addition, ADA also expresses her ``feelings'' and interact with occupants through laser beams, synthetic voices, and the illumination of the tiles. This creates an immersive environment which the occupants may feel like they have been brought inside ADA's ``dream''. 

At the Hyperbody Research Group\footnote{Hyperbody: \url{www.hyperbody.nl}}, Oosterhuis and colleagues established the Muscle Projects~\cite{Oosterhuis2008}, which is a series of interactive architecture that incorporates real-time actuated response. The Muscle Tower is a movable structure that changes its form in response to both the weather and the users. Its second iteration, The Muscle Tower 2, senses the people walking by using motion sensors. It then bends, twists, or deforms in response to the stimuli. Likewise, The Muscle Space creates an interactive passageway that moves in some dynamic patterns such as bending, twisting, folding, as people walking through it, triggering the pressure sensors on the floor. It acts as a living structure that tries to reach out to the passerby proactively.

Meanwhile, the Hylozoic Ground by Beesley et al.~\cite{Beesley2010} utilized a network of sensors and actuators that are distributed over a large space. The sculpture captures the presence of the users and responds by activating light patterns and kinetic movements of its frond-like mechanisms. Complex activation patterns emerge as responses from multiple triggers overlap. It entices the users to explore and interact with the sculpture in different ways by offering increasingly complex behaviours. Its large size also enables the users to be absorbed in the immersive environment created by the sculpture. 

However, these works are the non-varying type of Dynamic-Interactive system, as their responsive behaviours do not change. Over a longer term, as the visitors gain familiarity with the system, the system will become predictable and its effectiveness in engaging the users will consequently decrease. In this work, we aim to create a varying interactive artwork by emulating the characteristics of living organisms such as curiosity and learning. 

Metatopia~\cite{Metabody2014} is a dynamically evolving interactive arts that is a hybrid of architectural installation and performance. A set of flexible and mobile mesh panels form a space with a human performer at the centre of it. Animated digital images are projected from its centre to create an immersive environment. Dynamic and varying interactive behaviours arise from the exchange between the viewers and the system which embodies the human performer. In other word, Metatopia enables a varying-type of Dynamic-Interactive system by incorporating human as part of the system.

% More details about PBAI's work
Philip Beesley Architect Inc. (PBAI) develops art installations that exhibit qualities shared by living things~\cite{Gorbet2015}. The Hylozoic Series of interactive art sculptures use a distributed network of microcontrollers, actuators and sensors mounted within scaffolds of synthetic materials to engage the users. They detect the presence of the users primarily through infrared (IR) proximity sensors. The systems then respond with kinetic movements, sound effects, and visual illuminations. The kinetic movements are primarily actuated by shape memory alloy (SMA) wires that drive mechanisms made of flexible materials; sounds are generated by using vibration motors and audio players; and visual illuminations are provided by both low-power and high-power light emitting diodes (LED). 

Previous generations of the Hylozoic Series~\cite{Beesley2012} rely on the superpositions of multiple layers of these simple sets of prescripted activations to generate complexities in their responsive behaviours. The exact implementation of these prescripted behaviours varies in different installation projects. For instance, Aurora~\cite{PBAI-Simon} features an array of light chains that are suspended from the ceiling. Each light chain is made up of a spiral of LEDs with a IR proximity sensor at the bottom. When an IR proximity sensor detects a change in distance measurement above a certain threshold, it triggers the light chain to activate each of its LEDs successively with overlaps and dimming. In addition, neighbouring light chains would also activate in similar manner but at a lower level of intensity. Successive activations may superimpose onto existing activation patterns that have not completed yet. The interference among the activations patterns that are triggered at different times and locations creates complex emergent behaviours. This is analogous the interference patterns of waveforms. 

Although its interactive behaviours might seem fascinating at first, it is nevertheless a non-varying type of dynamic-interactive arts. A living system demonstrates growth and changes its behaviours over time. In addition, the prescripted nature of the responsive behaviours restricts the autonomy of the system as it would only behave exactly as its creators have intended. This work builds on the desire to integrate life-like qualities to the sculptural system beyond a superficial level by giving it the autonomy to generate its own behaviours that continuously adapt to a changing environment.



\section{Artificial Life and Developmental Robotics}

To emulate life-like behaviours, one can start by observing how human beings behave. Srinivasa and colleagues~\cite{Dragan2015}\cite{AncaDraga2014} modelled how human beings convey or mask their intentions through movement and applied these models to a humanoid robot. Similarly, Gielniak et al.~\cite{Gielniak2013} focused on making a robot's motion more understandable by emulating the coordinated effects of human joints. Those studies focused on making intent of the robots clear. In contrast, our objective is to make robots more engaging and life-like, where unpredictability might be a desirable quality. For instance, Dragan et al.~\cite{AncaDraga2014} showed that the robot's perceived intelligence increased when the participants believed that the robot was intentionally deceptive. Our work investigates whether unpredictable behaviours emerging from the learning process will appear more life-like and engaging.

Moreover, one of the open questions in artificial life research is whether we can demonstrate the emergence of intelligence and mind~\cite{Bedau2000}. In the Petting Zoo project by Minimaforms~\cite{Minimaforms}, they created pets that interact with human users and other pets through kinesis, sound, and light, and gradually develop personality. However, there is generally little in the literature that describes the technical details of this type of work, and it is unclear what their internal learning mechanisms are. Detailed analyses of their behaviours and exploration patterns have not been publically documented. 

In a more recent project, Ikegami built an artificial life system called Mind Time Machine~\cite{Ikegami2013} to demonstrate that self-organization can emerge from chaotic sensory flow in the real world. He applied adaptive neural networks on a system consisting of three projector screens and fifteen cameras. It consisted of three asynchronous subsystems which were only coupled optically through video feedback. Video frames from the cameras were mixed and projected based on the internal memory and the level of activity. Through inherent instabilities, partly due to changing lighting conditions and people movement, sporadic behaviours emerged. During times of inactivity, the system self-organized into default mode behaviours. Likewise, our system aims to discover systematic behaviours through curiosity-based learning and its interaction with the environment. 

The idea of emergence of structure and consciousness is explored in many previous works in the field of developmental robotics~\cite{Lungarella2003}\cite{Asada2009}. Prince at al. proposed that continuous integration of new skills is a the core concept in developmental robotics~\cite{Prince2005}. Kompella et al. developed SKILLABILITY~\cite{Kompella2014}, which is an algorithm that enables humanoid robots to learn complex skills from the raw pixels of video streams. It first builds lower-dimensional step-like abstractions, or slow features, using Curiosity Driven Modular Incremental Slow Feature Analysis (CD-MISFA)~\cite{Luciw2013}. These slow features then augment the robot's state-space. Its reward function rewards transitions that produce large change in these slow features, which correspond to high-level goals such as grasping or toppling. They showed that the robot was able to acquire recognition of high-level events and form complex action sets from pixel-level information. This shows that complex, yet structured, behaviours can emerge through explorations of unstructured and noisy data.

Lee et al. proposed a developmental system with multiple stages that are defined by competence levels~\cite{Lee2007}. Different constraints are placed at different stages to guide the development process. These constraints help reducing the complexity of inputs and actions, as well as the size of the task space. They allow the learning agents to focus on tasks that they have the maximum chance of learning. More difficult tasks can then be developed in subsequent stages by building onto the experience acquired in the levels before. However, this approach requires a priori knowledge of the tasks and a clear development path, and might not suitable for on-going developments without a specific goal.

Oudeyer et al. developed a learning mechanism called Intelligent Adaptive Curiosity~(IAC)~\cite{Oudeyer2007}, a reinforcement learning algorithm with the objective of maximizing learning progress. Their goal was to develop a robot that is capable of life-long learning. The robot makes sense of the mapping between its actuators and sensors through continuous self-experimentation, without explicit instruction from human experts. Fundamentally, the IAC is a reinforcement learning algorithm with an objective to maximize learning progress. Learning progress is defined as the reduction in prediction error. In other words, the agent seeks to explore the region of the sensorimotor space that leads to the highest improvement in prediction error. As a result, the algorithm avoids learning in the parts of sensorimotor space that are either too random or too predictable. This formulation leads to continual change in behaviour over time, as regions of the state space that are initially interesting become less interesting as the system becomes more knowledgeable about them. 

In the Playground Experiment~\cite{Oudeyer2005} the IAC was implemented on a Sony AIBO robot which acts based on five action parameters and detects the environment based on three binary high-level sensors. They showed that the robot was able to acquire complex interaction behaviours with the environment, which was necessary to improved its knowledge about the complex relationships between the sensorimotor contexts and the consequences. This draws parallels to the intrinsic human drive of curiosity, which is hypothesized to drive humans to try to explore areas that have the highest potential for learning new knowledge.
 
\section{Intrinsic Adaptive Curiosity}

An IAC system~\cite{Oudeyer2007} consists of two learning mechanisms, the Classic Machine learner (classM) and the Meta Machine learner (metaM). Based on the context (the sensors' inputs) and the action (the actuators' outputs), classM computes a prediction of the consequence, i.e., the resultant sensors' inputs at the next time step. Then, it implements the action and compares the actual consequence with the prediction and modifies its model in order to reduce the error in the subsequent prediction. The Meta Machine learner (metaM) predicts the error of classM. In other words, it estimates how accurately classM is able predict the consequence. The actual prediction error is then fed back to the metaM, and metaM modifies its estimate of prediction error of the newly modified classM. This change in the prediction error is recorded at each time step in the knowledge gain assessor (KGA). The KGA then computes the expected learning progress by calculating the change in error estimation. This expected learning progress is used as the reward, $R$. As classM prediction gets better in a given area of sensorimotor space, the expected learning progress diminishes and the reward for exploring that area gets smaller. Higher rewards in other as-yet unexplored regions encourage the algorithm to move on, to satisfy its ``curiosity''. 

One important feature of the IAC is the idea of regional experts. Each region collects exemplars of similar sensorimotor context, and has an expert that is trained on the exemplars in the region. Exemplars are the training data for the prediction model and they are collected as the system selects actions and observes the consequences. The ``features'' are a vector of the sensory inputs $S(t)$, and a vector of selected actions $M(t)$ at time $t$; and the ``labels'' are the resultant sensory inputs $S(t+1)$ at time $t+1$. The regional experts constrain the estimate of learning progress within their respective sensorimotor contexts $SM(t)$, which is a concatenation of the vectors $S(t)$ and $M(t)$. This is important because it allows each expert to use a simpler model, as it covers only a small region of the state space.  

The following are the steps for the learning algorithm \cite{Oudeyer2007}:

\begin{enumerate}
	\item \label{learning_start} Read sensory inputs $S(t)$
	\item Select action $M(t)$ using the $\epsilon$-greedy selection policy based on the knowledge gain potential, or the action value, $q$ of each region
	\item Consult expert specialized in the relevant sensorimotor context $SM(t)$ to predict the expected sensory inputs $S'(t+1)$
	\item Perform action $M(t)$
	\item Observe actual sensory inputs $S(t+1)$ and add to the expert's training set
	\item Compute prediction error $e(t+1) = \|S(t+1) - S'(t+1)\|_2$
	\item Compute the actual mean error $<e(t+1)>$ by taking the average error over a window of previous errors
	\item Compute the predicted mean error $<e(t+1-\tau)>$ by taking the average error over a window of previous errors with an offset $\tau$
	\item Compute the reward $R(SM(t)) = -[<e(t+1)> - <e(t+1-\tau)>]$
	\item Update the knowledge gain potential $q$ for the sensorimotor context $SM(t)$ based on $R(SM(t))$
	\item \label{learning_loop} Repeat \ref{learning_start} to \ref{learning_loop} indefinitely
\end{enumerate}

In this work, we adapt the IAC and apply it to the Hylozoic Series interactive art sculpture, which is a distributed sculptural system with a large number of sensors and actuators. This gives the sculpture the ability to generate its own behaviours through self-motivated learning. Its interaction with people and people's perceptions of it may be very different from the prescripted, responsive kinds of behaviours used in the previous generations of the system. Indeed, in the experiments done in \cite{Oudeyer2007}, the human observers were never part the environment that the robot tries to learn. This work focuses on examining the interaction between the learning system and human users, and how the two influence each other.

