\chapter[Related Work]{Related Work\footnote{Part of this chapter is adapted from paper published in IROS~2015~\cite{Chan2015}}} 
 \label{chap:related_work}

%TODO add an intro paragraph laying out the contents of this chapter here

\section{Interactive Arts}
Interactive arts can be categorized as Static, Dynamic-Passive, Dynamic-Interactive, and Dynamic-Interactive (varying) based on the degree of the interaction between the art works and the viewers \cite{Edmonds2004}. Dynamic-Interactive systems give the human viewers an active role in defining the behaviours of the system. This category introduces an agent that modifies the specifications of the art object. This additional unpredictability introduces a new dimension of complexity to the behaviours of the system. 

In \cite{Drummond2009}, Drummond examined the conceptual elements of interactive musical arts. For an interactive system to move beyond being simply a complex musical instrument with a direct reactive mapping from inputs to generation of sound, it must possess some level of autonomy in the composition and generation of music. In addition, the interactivity should be bilateral; the performer influences the music and the music influences the performer. 

These concepts can easily be extended to visual and kinetic arts. Visual-based interactive systems such as the Iamascope in Beta\_space \cite{Costello2005} and audio-based systems such as Variations \cite{Wands2005} engaged the participants by allowing them to directly affect the output of the system. %TODO  Describe these systems in more detail.  How exactly did the system generate autonomous responses?

Works in interactive architecture \cite{Beesley2010}\cite{Hangar.org} try to provide a responsive and immersive environment where the viewers can feel as if they belong to the system. %TODO Describe these systems in more detail  What exactly do they do?  How do they generate interactive behaviours?
However, most of these works are the non-varying type of Dynamic-Interactive system, as their responsive behaviours do not change. Over a longer term, as the visitors gain familiarity with the system, the system will become predictable and its effectiveness in engaging the users will consequently decrease. In this work, we aim to create a varying interactive artwork by emulating the characteristics of living organisms such as curiosity and learning. 

% More details about PBAI's work
Philip Beesley Architect Inc. (PBAI) develops art installations that exhibit qualities shared by living things \cite{Gorbet2015}. The Hylozoic Series interactive art sculptures use a distributed network of microcontrollers, actuators and sensors mounted within scaffolds of synthetic materials to engage the users. They detect the presence of the users primarily through infrared (IR) proximity sensors. The systems then respond by activating in form of kinetic movements, sound effects, and visual illuminations. The kinetic movements are primarily actuated by shape memory alloy (SMA) wires that drive mechanisms made of flexible materials; sounds are generated by using vibration motors and audio players; and visual illuminations are powered by both low-power and high-power light emitting diodes (LED). Previous generations of the series \cite{Beesley2012} rely on the superpositions of multiple layers of these simple sets of prescripted activations to generate complexities in their responsive behaviours. %TODO Describe these simple sets of behaviours
Though their interactive behaviours might seem fascinating at first, they are nevertheless a non-varying type of dynamic-interactive arts. A living system demonstrates growth and changes its behaviours over time. In addition, the prescripted nature of the responsive behaviours restricts the autonomy of the system as it would only behave exactly as its creators have intended. This work builds on the desire to integrate life-like qualities to the sculptural system beyond a superficial level by giving it the autonomy to generate its own behaviours that are continuously changing.

%TODO This review of the literature seems very sparse.  Are there any other interactive architecture systems?  What about the work of the hyperbody group?  This section needs to be beefed up substantially.  It is not sufficient to only cite the work we are involved with.  Please look at some of the work cited in the NGB paper and add a discussion about it here.

\section{Artificial Life and Developmental Robotics}

To emulate life-like behaviours, one can start by observing how human beings behave. Srinivasa and colleagues \cite{Dragan2015}\cite{AncaDraga2014} modelled how human beings convey or mask their intentions through movement and applied these models to a humanoid robot. Similarly, Gielniak et al. \cite{Gielniak2013} focused on making the robot's motion more understandable by emulating the coordinated effects of human joints. Those studies focused on making the intent of the robots clear. In contrast, our objective is to make robots more engaging and life-like, where unpredictability might be a desirable quality. For instance, Dragan et al. \cite{AncaDraga2014} showed that the robot's perceived intelligence increased when the participants believed that the robot was intentionally deceptive. Our work investigates whether unpredictable behaviours emerging from the learning process will appear more life-like and engaging.
%TODO Again, this review is very sparse.  You need to add more detail here, to demonstrate that you are aware of the literature and how it relates to our work.

Moreover, one of the open questions in artificial life research is whether we can demonstrate the emergence of intelligence and mind \cite{Bedau2000}, examined in projects such as the Petting Zoo by Minimaforms \cite{Minimaforms} and Mind Time Machine \cite{Ikegami2013}. The idea of emergence of structure and consciousness is explored in many previous works in the field of developmental robotics \cite{Lungarella2003}\cite{Asada2009}\cite{Kompella2014}. %TODO describe all of these work in more detail.  What do they do, and how is it relevant for/compares to our work?

Oudeyer et al. developed a learning mechanism called Intelligent Adaptive Curiosity (IAC) \cite{Oudeyer2007}, a reinforcement learning algorithm with the objective of maximizing learning progress. Their goal 
was to develop a robot that is capable of life-long learning. The robot makes sense of the mapping between its actuators and sensors through continuous self-experimentation, without explicit instruction from human experts. Fundamentally, the IAC is a reinforcement learning algorithm with an objective to maximize learning progress. Learning progress is defined as the reduction in prediction error. In other words, the agent seeks to explore the region of the sensorimotor space that leads to the highest improvement in prediction error. As a result, the algorithm avoids learning in the parts of sensorimotor space that are either too random or too predictable. This formulation leads to continual change in behaviour over time, as regions of the state space that are initially interesting become less interesting as the system becomes more knowledgeable about them. 

In the Playground Experiment \cite{Oudeyer2005} the IAC was implemented on a Sony AIBO robot which acts based on five action parameters and detects the environment based on three binary high-level sensors. They showed that the robot was able to acquire complex interaction behaviours with the environment, which was necessary to improved its knowledge about the complex relationships between the sensorimotor contexts and the consequences. This draws parallels to the intrinsic human drive of curiosity, which is hypothesized to drive humans to try to explore areas that have the highest potential for learning new knowledge.
 
\section{Intrinsic Adaptive Curiosity}

An IAC system \cite{Oudeyer2007} consists of two learning mechanisms, the Classic Machine learner (classM) and the Meta Machine learner (metaM). Based on the context (the sensors' inputs) and the action (the actuators' outputs), classM computes a prediction of the consequence, i.e., the resultant sensors' inputs at the next time step. Then, it implements the action and compares the actual consequence with the prediction and modifies its model in order to reduce the error in the subsequent prediction. The Meta Machine learner (metaM) predicts the error of classM. In other words, it estimates how accurately classM is able predict the consequence. The actual prediction error is then fed back to the metaM, and metaM modifies its estimate of prediction error of the newly modified classM. This change in the prediction error is recorded at each time step in the knowledge gain assessor (KGA). The KGA then computes the expected learning progress by calculating the change in error estimation. This expected learning progress is used as the reward, $R$, as classM prediction gets better in a given area of sensorimotor space, the expected learning progress diminishes and the reward for exploring that area gets smaller. Higher rewards in other as-yet unexplored regions encourage the algorithm to move on, to satisfy its ``curiosity''. 

One important feature of the IAC is the idea of regional experts. Each region collects exemplars of similar sensorimotor context, and has an expert that is trained on the exemplars in the region. Exemplars are the training data for the prediction model and they are collected as the system selects actions and observes the consequences. The ``features'' are a vector of the sensory inputs $S(t)$, and a vector of selected actions $M(t)$ at time $t$; and the ``labels'' are the resultant sensory inputs $S(t+1)$ at time $t+1$. The regional experts constrain the estimate of learning progress within their respective sensorimotor contexts $SM(t)$, which is a concatenation of the vectors $S(t)$ and $M(t)$. This is important because it allows each expert to use a simpler model, as it covers only a small region of the state space.  

The following are the steps for the learning algorithm \cite{Oudeyer2007}:

\begin{enumerate}
	\item \label{learning_start} Read sensory inputs $S(t)$
	\item Select action $M(t)$ with the highest predicted learning progress $R(SM(t))$ based on $\epsilon$-greedy selection policy
	\item Consult expert specialized in the relevant sensorimotor context $SM(t)$ to predict the expected sensory inputs $S(t+1)'$
	\item Perform action $M(t)$
	\item Observe actual sensory inputs $S(t+1)$ and add to the expert's training set
	\item Compute prediction error $e(t+1) = |S(t+1) - S(t+1)'|$
	\item Compute the change in prediction error $R(SM(t)) = -[e(t+1) - e(t)]$
	\item Update the learning progress for the sensorimotor context $SM(t)$ based on $R(SM(t))$
	\item \label{learning_loop} Repeat \ref{learning_start} to \ref{learning_loop} indefinitely
\end{enumerate}

In this work, we adapt the IAC and apply it to the Hylozoic Series interactive art sculpture, which is a distributed sculptural system with a large number of sensors and actuators. This gives the sculpture the ability to generate its own behaviours through self-motivated learning. Its interaction with people and people's perceptions of it may be very different from the prescripted, responsive kinds of behaviours used in the previous generations of the system. Indeed, in the experiments done in \cite{Oudeyer2007}, the human observers were never part the environment that the robot tries to learn. This work focuses on examining the interaction between the learning system and human users, and how the two influence each other.

